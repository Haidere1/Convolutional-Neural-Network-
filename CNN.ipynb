{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib15YBU4VDt4",
        "outputId": "3973a001-e18b-473d-891c-10e9a987ce49"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 15, 15, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                65600     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122570 (478.79 KB)\n",
            "Trainable params: 122570 (478.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 117s 74ms/step - loss: 1.7656 - accuracy: 0.3405 - val_loss: 1.4092 - val_accuracy: 0.4818\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 115s 74ms/step - loss: 1.4919 - accuracy: 0.4563 - val_loss: 1.2696 - val_accuracy: 0.5421\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 117s 75ms/step - loss: 1.3694 - accuracy: 0.5052 - val_loss: 1.2976 - val_accuracy: 0.5433\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 111s 71ms/step - loss: 1.2925 - accuracy: 0.5353 - val_loss: 1.1473 - val_accuracy: 0.5965\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 107s 68ms/step - loss: 1.2357 - accuracy: 0.5592 - val_loss: 1.1321 - val_accuracy: 0.6024\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 107s 69ms/step - loss: 1.1963 - accuracy: 0.5729 - val_loss: 1.0589 - val_accuracy: 0.6253\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 1.1604 - accuracy: 0.5864 - val_loss: 0.9902 - val_accuracy: 0.6503\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 1.1317 - accuracy: 0.5976 - val_loss: 0.9874 - val_accuracy: 0.6502\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 1.1028 - accuracy: 0.6092 - val_loss: 0.9680 - val_accuracy: 0.6576\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 107s 68ms/step - loss: 1.0910 - accuracy: 0.6142 - val_loss: 0.9575 - val_accuracy: 0.6668\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 107s 68ms/step - loss: 1.0685 - accuracy: 0.6204 - val_loss: 0.9919 - val_accuracy: 0.6446\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 1.0525 - accuracy: 0.6295 - val_loss: 0.9775 - val_accuracy: 0.6615\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 107s 68ms/step - loss: 1.0409 - accuracy: 0.6322 - val_loss: 0.8911 - val_accuracy: 0.6889\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 107s 69ms/step - loss: 1.0318 - accuracy: 0.6338 - val_loss: 0.9488 - val_accuracy: 0.6645\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.0130 - accuracy: 0.6415 - val_loss: 0.8754 - val_accuracy: 0.6942\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 103s 66ms/step - loss: 1.0052 - accuracy: 0.6436 - val_loss: 0.9078 - val_accuracy: 0.6895\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 107s 68ms/step - loss: 0.9928 - accuracy: 0.6506 - val_loss: 0.9433 - val_accuracy: 0.6741\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 107s 68ms/step - loss: 0.9894 - accuracy: 0.6498 - val_loss: 0.8337 - val_accuracy: 0.7042\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 0.9771 - accuracy: 0.6559 - val_loss: 0.8606 - val_accuracy: 0.6962\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 107s 69ms/step - loss: 0.9754 - accuracy: 0.6573 - val_loss: 0.8226 - val_accuracy: 0.7122\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 0.9636 - accuracy: 0.6625 - val_loss: 0.9534 - val_accuracy: 0.6789\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 106s 68ms/step - loss: 0.9531 - accuracy: 0.6633 - val_loss: 0.8361 - val_accuracy: 0.7057\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 107s 69ms/step - loss: 0.9473 - accuracy: 0.6663 - val_loss: 0.8151 - val_accuracy: 0.7176\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 0.9402 - accuracy: 0.6679 - val_loss: 0.8354 - val_accuracy: 0.7085\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 107s 69ms/step - loss: 0.9302 - accuracy: 0.6735 - val_loss: 0.8283 - val_accuracy: 0.7112\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 107s 68ms/step - loss: 0.9246 - accuracy: 0.6749 - val_loss: 0.8416 - val_accuracy: 0.7075\n",
            "313/313 - 4s - loss: 0.8151 - accuracy: 0.7176 - 4s/epoch - 12ms/step\n",
            "\n",
            "Test accuracy: 0.7175999879837036\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# The following LOC loads the data set that we have to check\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#To normalize the pixel values:\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# I converted it to binary class matrice because im using softmax.\n",
        "# activation function for the output layer thats why\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# CNN Model Architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Define early stopping callback\n",
        "# This bit of code is to stop the model if we are getting the same accuracy at the end of each epoch\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# The following lines will train the model with early stopping\n",
        "history = model.fit(data_generator.flow(x_train, y_train, batch_size=32),\n",
        "                    epochs=100,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model to check the accuracy of our model\n",
        "# the term verbose=2 is just to show the progress while running the code\n",
        "#verbose 2 means a progress bar for each epoch\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "# Finallt we will save the mode with the name\n",
        "model.save('LAB_FINAL_TRANED_MODEL_SP21_BSE_001.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "ThOyucrVgyqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# First we will load the model that we trained earlier\n",
        "\n",
        "model = load_model('/content/LAB_FINAL_TRANED_MODEL_SP21_BSE_001.h5')\n",
        "\n",
        "# we load and pre process the image that we want to predict the class of!\n",
        "\n",
        "img_path = '/content/trk.jpg'\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0\n",
        "\n",
        "# feed the image to the mode to make the prediction\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# in CIFAR-10 the classes are labled with integer values from 0-9 so i've provided the names of each\n",
        "#class for better understanding!!!\n",
        "\n",
        "predicted_class = np.argmax(prediction)\n",
        "class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if 0 <= predicted_class < len(class_names):\n",
        "    predicted_class_name = class_names[predicted_class]\n",
        "    print(f'Predicted Class: {predicted_class_name}')\n",
        "else:\n",
        "    print(f'Invalid Predicted Class Index: {predicted_class}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaoA1t2egzqC",
        "outputId": "d9c09c0c-c1e0-487f-f71f-476b46086e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 80ms/step\n",
            "Predicted Class: Truck\n"
          ]
        }
      ]
    }
  ]
}